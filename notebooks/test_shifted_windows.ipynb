{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a540d33-710a-4733-948f-ada5bc5a93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6e30d6-6641-4c91-9952-18b569c4363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from torch import nn, einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd76c76-35d0-4c58-bcd0-0916ee0aeb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swin.model import PatchMerging, CyclicShift, WindowAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb5ac4d-5565-41a5-a988-8534fb89272d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functional Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7129feb-268d-484f-a228-0ba19ddf1231",
   "metadata": {},
   "source": [
    "There are some interesting functional approaches to structure resdiual and layer norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae142cf-4b6c-4688-8c7d-4a951ea2e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "    \n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac6685-db26-4d68-b163-d9d4668c4cbe",
   "metadata": {},
   "source": [
    "Now I can compose residual with any other inner block. This is pretty neat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95796968-e616-491d-9e11-ecd203f90887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck = nn.Sequential(\n",
    "    nn.Linear(128, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 128),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "res_block = Residual(bottleneck)\n",
    "\n",
    "x = torch.rand(1, 4, 4, 128)\n",
    "y = res_block(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50239f-b416-4a43-812c-b076d0aee837",
   "metadata": {},
   "source": [
    "Extend the same functional concept to `LayerNorm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2527f10b-c97b-4e3d-99c6-524694442d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, embed_dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c732b882-71b7-4c6d-86fa-2881f89ce94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_block = PreNorm(128, nn.Sequential(\n",
    "    nn.Linear(128, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 128),\n",
    "    nn.ReLU(),\n",
    "))\n",
    "\n",
    "x = torch.rand(1, 4, 4, 128)\n",
    "y = norm_block(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eedafc-415a-450a-b962-367b4821e2ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Patch Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2ec11-e26e-4ef3-ab23-bfd98df64bff",
   "metadata": {},
   "source": [
    "If I have an image `(3, 16, 16)`, and I designate patch size to be `(3, 4, 4)`. Then I should have 16 patches and each patch contains 48 values from `3x4x4`.\n",
    "\n",
    "The `Unfold` module extracts sliding local blocks from a batched input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60e6329-02b4-4ef2-9ae8-cecfbb1c3d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image torch.Size([1, 3, 16, 16])\n",
      "Unfolded torch.Size([1, 48, 16]) contains 16 patches with each has 4x4x3 dimensions\n",
      "View as image patches torch.Size([1, 48, 4, 4])\n",
      "Move patch values to last axis torch.Size([1, 4, 4, 48])\n",
      "Final output torch.Size([1, 4, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "patch_size = 4\n",
    "out_dim = 32\n",
    "chan_dim = 3\n",
    "\n",
    "unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "linear = nn.Linear(chan_dim * patch_size * patch_size, out_dim)\n",
    "\n",
    "x = torch.rand(1, chan_dim, 16, 16)\n",
    "print('Image', x.shape)\n",
    "x = unfold(x)\n",
    "print('Unfolded', x.shape, 'contains 16 patches with each has 4x4x3 dimensions')\n",
    "x = x.view(1, -1, patch_size, patch_size)\n",
    "print('View as image patches', x.shape)\n",
    "x = x.permute(0, 2, 3, 1)\n",
    "print('Move patch values to last axis', x.shape)\n",
    "y = linear(x)\n",
    "print('Final output', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7df2567-0d9d-431c-9201-ff0e2e78c950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 16, 16)\n",
    "y = PatchMerging(chan_dim, out_dim, downscaling_factor=4)(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574a589-b311-4a9e-9786-29a66cde9d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Window Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a263ea3-3b0a-4a25-ba03-ed48ccd89099",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cyclic Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041386c-02b6-4453-8d67-ed377d62452b",
   "metadata": {},
   "source": [
    "Suppose the input has 8 by 8 patches and each patch has embedding dimension 32, let's create 4 windows. When we apply cyclic shift, the displacement will shift the element by `(i, j)` amount. In the following example, the shift pushes every element by `(2, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2aec8f2-9398-4d17-94e6-56734884d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12., 13., 14., 15., 16.],\n",
      "        [17., 18., 19., 20., 21., 22., 23., 24.],\n",
      "        [25., 26., 27., 28., 29., 30., 31., 32.],\n",
      "        [33., 34., 35., 36., 37., 38., 39., 40.],\n",
      "        [41., 42., 43., 44., 45., 46., 47., 48.],\n",
      "        [49., 50., 51., 52., 53., 54., 55., 56.],\n",
      "        [57., 58., 59., 60., 61., 62., 63., 64.]])\n",
      "tensor([[55., 56., 49., 50., 51., 52., 53., 54.],\n",
      "        [63., 64., 57., 58., 59., 60., 61., 62.],\n",
      "        [ 7.,  8.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [15., 16.,  9., 10., 11., 12., 13., 14.],\n",
      "        [23., 24., 17., 18., 19., 20., 21., 22.],\n",
      "        [31., 32., 25., 26., 27., 28., 29., 30.],\n",
      "        [39., 40., 33., 34., 35., 36., 37., 38.],\n",
      "        [47., 48., 41., 42., 43., 44., 45., 46.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 8, 8, 32)\n",
    "\n",
    "# Make it more readable, assign 1...64 to the first element of each embedding.\n",
    "x[:, :, :, 0] = torch.arange(1, 65).view(8, 8)\n",
    "\n",
    "window_size = 4\n",
    "displacement = window_size // 2\n",
    "\n",
    "print(x[0, :, :, 0])\n",
    "shifted_x = torch.roll(x, shifts=(displacement, displacement), dims=(1, 2))\n",
    "print(shifted_x[0, :, :, 0])\n",
    "shifted_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37cb759-721d-4640-bc46-3fb1cfea2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12., 13., 14., 15., 16.],\n",
      "        [17., 18., 19., 20., 21., 22., 23., 24.],\n",
      "        [25., 26., 27., 28., 29., 30., 31., 32.],\n",
      "        [33., 34., 35., 36., 37., 38., 39., 40.],\n",
      "        [41., 42., 43., 44., 45., 46., 47., 48.],\n",
      "        [49., 50., 51., 52., 53., 54., 55., 56.],\n",
      "        [57., 58., 59., 60., 61., 62., 63., 64.]])\n",
      "tensor([[55., 56., 49., 50., 51., 52., 53., 54.],\n",
      "        [63., 64., 57., 58., 59., 60., 61., 62.],\n",
      "        [ 7.,  8.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [15., 16.,  9., 10., 11., 12., 13., 14.],\n",
      "        [23., 24., 17., 18., 19., 20., 21., 22.],\n",
      "        [31., 32., 25., 26., 27., 28., 29., 30.],\n",
      "        [39., 40., 33., 34., 35., 36., 37., 38.],\n",
      "        [47., 48., 41., 42., 43., 44., 45., 46.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 8, 8, 32)\n",
    "x[:, :, :, 0] = torch.arange(1, 65).view(8, 8)\n",
    "\n",
    "print(x[0, :, :, 0])\n",
    "shifted_x = CyclicShift(displacement)(x)\n",
    "print(shifted_x[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21c117-9f70-4684-8789-54a000364e67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Relative Position Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d2ccb-0524-408c-9674-08d32b60bb42",
   "metadata": {},
   "source": [
    "Each window contains `(M, M)` patches. The `M` is the window size. Now each patch needs to learn a relative position embedding. `M**2` is the number of patches in each window.\n",
    "\n",
    "If we don't use relative position, then the position embedding is a matrix of `(M**2, M**2)`. It's every position to every position.\n",
    "\n",
    "If we use relative position, then relative position along each axis lies in the range of `[-M + 1, M - 1]`, i.e. if `M = 4`, then we have `[-3, -2, -1, 0, 1, 2, 3]` for each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "586e4f73-1737-4b26-acbe-ffabb1548da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n",
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [0, 3],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 2],\n",
      "        [1, 3],\n",
      "        [2, 0],\n",
      "        [2, 1],\n",
      "        [2, 2],\n",
      "        [2, 3],\n",
      "        [3, 0],\n",
      "        [3, 1],\n",
      "        [3, 2],\n",
      "        [3, 3]])\n",
      "torch.Size([16, 16, 2])\n"
     ]
    }
   ],
   "source": [
    "window_size = 4\n",
    "indices = np.array([[x, y] for x in range(window_size) for y in range(window_size)])\n",
    "indices = torch.tensor(indices)\n",
    "print(indices.shape)\n",
    "print(indices)\n",
    "distances = indices[None, :, :] - indices[:, None, :]\n",
    "print(distances.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f90c3c-4a2b-45d3-abd2-2b42bd1be473",
   "metadata": {},
   "source": [
    "We have 16 to 16 positions, the distances cache the offset between `positions[i]` to `positions[j]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb79c6a4-9e80-43a7-89e1-cebd42d307c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e4e88cb-fe09-457d-8cf1-fce4f9913ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28818147-c2e3-408c-993c-5c00c03e716b",
   "metadata": {},
   "source": [
    "This will return all the `i` offsets for all 16 positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f1f4f12-38dc-4eec-b781-ffaee7344a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3],\n",
       "        [ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3],\n",
       "        [ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3],\n",
       "        [ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3],\n",
       "        [-1, -1, -1, -1,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2],\n",
       "        [-1, -1, -1, -1,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2],\n",
       "        [-1, -1, -1, -1,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2],\n",
       "        [-1, -1, -1, -1,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2],\n",
       "        [-2, -2, -2, -2, -1, -1, -1, -1,  0,  0,  0,  0,  1,  1,  1,  1],\n",
       "        [-2, -2, -2, -2, -1, -1, -1, -1,  0,  0,  0,  0,  1,  1,  1,  1],\n",
       "        [-2, -2, -2, -2, -1, -1, -1, -1,  0,  0,  0,  0,  1,  1,  1,  1],\n",
       "        [-2, -2, -2, -2, -1, -1, -1, -1,  0,  0,  0,  0,  1,  1,  1,  1],\n",
       "        [-3, -3, -3, -3, -2, -2, -2, -2, -1, -1, -1, -1,  0,  0,  0,  0],\n",
       "        [-3, -3, -3, -3, -2, -2, -2, -2, -1, -1, -1, -1,  0,  0,  0,  0],\n",
       "        [-3, -3, -3, -3, -2, -2, -2, -2, -1, -1, -1, -1,  0,  0,  0,  0],\n",
       "        [-3, -3, -3, -3, -2, -2, -2, -2, -1, -1, -1, -1,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae561745-8d74-4df9-98c5-05786b1f65ba",
   "metadata": {},
   "source": [
    "This will return all the `j` offsets for all 16 positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad466fe1-a188-4009-b0a3-0ba1043112d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3],\n",
       "        [-1,  0,  1,  2, -1,  0,  1,  2, -1,  0,  1,  2, -1,  0,  1,  2],\n",
       "        [-2, -1,  0,  1, -2, -1,  0,  1, -2, -1,  0,  1, -2, -1,  0,  1],\n",
       "        [-3, -2, -1,  0, -3, -2, -1,  0, -3, -2, -1,  0, -3, -2, -1,  0],\n",
       "        [ 0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3],\n",
       "        [-1,  0,  1,  2, -1,  0,  1,  2, -1,  0,  1,  2, -1,  0,  1,  2],\n",
       "        [-2, -1,  0,  1, -2, -1,  0,  1, -2, -1,  0,  1, -2, -1,  0,  1],\n",
       "        [-3, -2, -1,  0, -3, -2, -1,  0, -3, -2, -1,  0, -3, -2, -1,  0],\n",
       "        [ 0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3],\n",
       "        [-1,  0,  1,  2, -1,  0,  1,  2, -1,  0,  1,  2, -1,  0,  1,  2],\n",
       "        [-2, -1,  0,  1, -2, -1,  0,  1, -2, -1,  0,  1, -2, -1,  0,  1],\n",
       "        [-3, -2, -1,  0, -3, -2, -1,  0, -3, -2, -1,  0, -3, -2, -1,  0],\n",
       "        [ 0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3],\n",
       "        [-1,  0,  1,  2, -1,  0,  1,  2, -1,  0,  1,  2, -1,  0,  1,  2],\n",
       "        [-2, -1,  0,  1, -2, -1,  0,  1, -2, -1,  0,  1, -2, -1,  0,  1],\n",
       "        [-3, -2, -1,  0, -3, -2, -1,  0, -3, -2, -1,  0, -3, -2, -1,  0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b653306d-295d-4aad-941b-a7928e2aff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding = nn.Parameter(torch.randn(2 * window_size - 1, 2 * window_size - 1))\n",
    "pos_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c4e6e9c-0c05-4840-9d1b-fb627260e617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding[distances[:, :, 0], distances[:, :, 1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a60a25e-65ef-4f46-9fb3-e0e89adf56e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7837, -0.5602, -1.3962, -0.1333,  1.1046, -0.1810,  0.4121,  0.3423,\n",
       "         -0.7281,  0.1334, -1.5607, -0.5599, -1.7256,  1.0132,  0.3025,  0.6772],\n",
       "        [ 1.0940, -0.7837, -0.5602, -1.3962,  0.3335,  1.1046, -0.1810,  0.4121,\n",
       "         -0.6759, -0.7281,  0.1334, -1.5607, -2.1741, -1.7256,  1.0132,  0.3025],\n",
       "        [-0.1669,  1.0940, -0.7837, -0.5602, -0.1543,  0.3335,  1.1046, -0.1810,\n",
       "         -0.0026, -0.6759, -0.7281,  0.1334, -0.1207, -2.1741, -1.7256,  1.0132],\n",
       "        [ 1.2826, -0.1669,  1.0940, -0.7837,  0.0882, -0.1543,  0.3335,  1.1046,\n",
       "         -0.2839, -0.0026, -0.6759, -0.7281,  0.0742, -0.1207, -2.1741, -1.7256],\n",
       "        [-0.1886,  0.0454,  0.5713, -0.0612, -0.7837, -0.5602, -1.3962, -0.1333,\n",
       "          1.1046, -0.1810,  0.4121,  0.3423, -0.7281,  0.1334, -1.5607, -0.5599],\n",
       "        [ 1.0942, -0.1886,  0.0454,  0.5713,  1.0940, -0.7837, -0.5602, -1.3962,\n",
       "          0.3335,  1.1046, -0.1810,  0.4121, -0.6759, -0.7281,  0.1334, -1.5607],\n",
       "        [-0.3393,  1.0942, -0.1886,  0.0454, -0.1669,  1.0940, -0.7837, -0.5602,\n",
       "         -0.1543,  0.3335,  1.1046, -0.1810, -0.0026, -0.6759, -0.7281,  0.1334],\n",
       "        [ 0.0580, -0.3393,  1.0942, -0.1886,  1.2826, -0.1669,  1.0940, -0.7837,\n",
       "          0.0882, -0.1543,  0.3335,  1.1046, -0.2839, -0.0026, -0.6759, -0.7281],\n",
       "        [ 0.9197, -0.9413, -0.4521, -0.7931, -0.1886,  0.0454,  0.5713, -0.0612,\n",
       "         -0.7837, -0.5602, -1.3962, -0.1333,  1.1046, -0.1810,  0.4121,  0.3423],\n",
       "        [-1.5651,  0.9197, -0.9413, -0.4521,  1.0942, -0.1886,  0.0454,  0.5713,\n",
       "          1.0940, -0.7837, -0.5602, -1.3962,  0.3335,  1.1046, -0.1810,  0.4121],\n",
       "        [ 0.8137, -1.5651,  0.9197, -0.9413, -0.3393,  1.0942, -0.1886,  0.0454,\n",
       "         -0.1669,  1.0940, -0.7837, -0.5602, -0.1543,  0.3335,  1.1046, -0.1810],\n",
       "        [-1.6805,  0.8137, -1.5651,  0.9197,  0.0580, -0.3393,  1.0942, -0.1886,\n",
       "          1.2826, -0.1669,  1.0940, -0.7837,  0.0882, -0.1543,  0.3335,  1.1046],\n",
       "        [-0.3916,  1.4385, -0.6740,  1.5757,  0.9197, -0.9413, -0.4521, -0.7931,\n",
       "         -0.1886,  0.0454,  0.5713, -0.0612, -0.7837, -0.5602, -1.3962, -0.1333],\n",
       "        [-0.8120, -0.3916,  1.4385, -0.6740, -1.5651,  0.9197, -0.9413, -0.4521,\n",
       "          1.0942, -0.1886,  0.0454,  0.5713,  1.0940, -0.7837, -0.5602, -1.3962],\n",
       "        [ 1.3220, -0.8120, -0.3916,  1.4385,  0.8137, -1.5651,  0.9197, -0.9413,\n",
       "         -0.3393,  1.0942, -0.1886,  0.0454, -0.1669,  1.0940, -0.7837, -0.5602],\n",
       "        [ 1.5396,  1.3220, -0.8120, -0.3916, -1.6805,  0.8137, -1.5651,  0.9197,\n",
       "          0.0580, -0.3393,  1.0942, -0.1886,  1.2826, -0.1669,  1.0940, -0.7837]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding[distances[:, :, 0], distances[:, :, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d231b-2337-4d1a-9f32-d4ef7e2f8b61",
   "metadata": {},
   "source": [
    "Since we defined position embedding to be a parameter, these values will be learned and updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e8e69-d728-4f3f-862d-12c96558838b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Local Window Masking for Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dbed9d-f02d-441b-a475-4483301b23f6",
   "metadata": {},
   "source": [
    "The input will be re-arrange into windows. Within each window, we have `(4, 4)` patches with window size 4. The mask is applied after position embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c06037e-b598-4864-b3ab-65ccc3e66afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 4\n",
    "displacement = window_size // 2\n",
    "\n",
    "upper_lower_mask = torch.zeros(window_size**2, window_size**2)\n",
    "print(upper_lower_mask.shape) # Same shape as relative position embedding.\n",
    "\n",
    "upper_lower_mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n",
    "upper_lower_mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n",
    "\n",
    "upper_lower_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d64a0880-eefb-40df-9c4f-65456f4c6389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16])\n",
      "torch.Size([4, 4, 4, 4])\n",
      "torch.Size([16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
       "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
       "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
       "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
       "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
       "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
       "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
       "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
       "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
       "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
       "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
       "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
       "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
       "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
       "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
       "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 4\n",
    "displacement = window_size // 2\n",
    "\n",
    "left_right_mask = torch.zeros(window_size**2, window_size**2)\n",
    "print(left_right_mask.shape) # Same shape as relative position embedding.\n",
    "\n",
    "left_right_mask = rearrange(left_right_mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n",
    "print(left_right_mask.shape)\n",
    "left_right_mask[:, -displacement:, :, :-displacement] = float('-inf')\n",
    "left_right_mask[:, :-displacement, :, -displacement:] = float('-inf')\n",
    "left_right_mask = rearrange(left_right_mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
    "print(left_right_mask.shape)\n",
    "\n",
    "left_right_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bff10d-ded3-4420-80ab-3ebab722d717",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Window Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072405ea-d9af-4b52-82b0-39206847456b",
   "metadata": {},
   "source": [
    "After the window partition, my input is a batch tensor with patches and embedding dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9040b4d-3acd-490b-9be8-594dc9e02aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 4\n",
    "H = 16 # unit of patches\n",
    "W = 16 # unit of patches\n",
    "embed_dim = 64\n",
    "head_dim = 128\n",
    "num_heads = 8\n",
    "window_size = 4 # unit of patches\n",
    "\n",
    "x = torch.rand(B, H, W, embed_dim)\n",
    "to_qkv = nn.Linear(embed_dim, 3 * num_heads * head_dim)\n",
    "to_out = nn.Linear(num_heads * head_dim, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ec2646c-19a1-4b3c-a225-3c051714e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = to_qkv(x).chunk(3, dim=-1)\n",
    "num_win_h = H // window_size # Number of windows along height axis\n",
    "num_win_w = W // window_size # Number of windows along width axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a3767-2083-456f-a0fa-6b6ec261f93b",
   "metadata": {},
   "source": [
    "Each query, key, value tensor is of shape `(batch_size, num_heads, num_windows, num_patches, head_dim)`. In the example below, there are\n",
    "\n",
    "- Each sample has 8 heads\n",
    "- Each head has 16 windows, because (16,16) patches can be divided into 16 (4, 4) windows.\n",
    "- Each window has 16 patches\n",
    "- Each patch has 128 head dimension for computing attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6944f3c-2548-480c-9f5c-87f65c91b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q torch.Size([4, 8, 16, 16, 128])\n",
      "K torch.Size([4, 8, 16, 16, 128])\n",
      "V torch.Size([4, 8, 16, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "q, k, v = map(\n",
    "    lambda t: rearrange(t, 'b (num_win_h win_h) (num_win_w win_w) (h d) -> b h (num_win_h num_win_w) (win_h win_w) d',\n",
    "                        h=num_heads,\n",
    "                        win_h=window_size,\n",
    "                        win_w=window_size), qkv)\n",
    "\n",
    "print('Q', q.shape)\n",
    "print('K', k.shape)\n",
    "print('V', v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f819231-b189-4899-a8c1-c0829d4035ac",
   "metadata": {},
   "source": [
    "The attention score will be computed with dot product of `Q` and `K`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be350ff4-b6cf-4a06-939d-910a4c4ece0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16, 16, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dots = einsum('b h w i d, b h w j d -> b h w i j', q, k)\n",
    "dots.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6626f-44ee-4ed6-86e9-ee9ecd81136b",
   "metadata": {},
   "source": [
    "Positional embedding and masking will be added to the dot product and then perform softmax. I will skip it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "582effc3-2a87-4ca1-bc9b-b182e69c6927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax torch.Size([4, 8, 16, 16, 16])\n",
      "Another matrix product torch.Size([4, 8, 16, 16, 128])\n",
      "Rearranged back to patch format torch.Size([4, 16, 16, 1024])\n"
     ]
    }
   ],
   "source": [
    "attn = dots.softmax(dim=-1)\n",
    "print('Softmax', attn.shape)\n",
    "\n",
    "out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
    "print('Another matrix product', out.shape)\n",
    "\n",
    "out = rearrange(out, 'b h (num_win_h num_win_w) (win_h win_w) d -> b (num_win_h win_h) (num_win_w win_w) (h d)',\n",
    "                h=num_heads,\n",
    "                win_h=window_size,\n",
    "                win_w=window_size,\n",
    "                num_win_h=num_win_h,\n",
    "                num_win_w=num_win_w)\n",
    "print('Rearranged back to patch format', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d7fce4-860b-4e7c-8d64-45ef17bb66f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 16, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_out(out).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373bd062-a815-485a-b0ec-2c6716e4e895",
   "metadata": {},
   "source": [
    "Since the input has 16 patches, the attention score is 16 to 16 self-attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044454f-74e9-4923-b523-ac03fc800940",
   "metadata": {},
   "source": [
    "## Shifted Window Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73cea3-9381-4a4a-b07e-a36884077b08",
   "metadata": {},
   "source": [
    "Same as above but I will apply a cyclic shift before computing attention score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1936e8b5-4b04-4583-95d4-1b507b45120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 4\n",
    "H = 16 # unit of patches\n",
    "W = 16 # unit of patches\n",
    "embed_dim = 64\n",
    "head_dim = 128\n",
    "num_heads = 8\n",
    "window_size = 4 # unit of patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31f5f765-9f64-4afc-a1de-a729f2f8f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(B, H, W, embed_dim)\n",
    "shift_forward = CyclicShift(-window_size // 2)\n",
    "shift_backward = CyclicShift(window_size // 2)\n",
    "\n",
    "to_qkv = nn.Linear(embed_dim, 3 * num_heads * head_dim)\n",
    "to_out = nn.Linear(num_heads * head_dim, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa91a2f4-da9e-4bfb-8c0b-3feeb6f7d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q torch.Size([4, 8, 16, 16, 128])\n",
      "K torch.Size([4, 8, 16, 16, 128])\n",
      "V torch.Size([4, 8, 16, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "shifted_x = shift_forward(x)\n",
    "qkv = to_qkv(shifted_x).chunk(3, dim=-1)\n",
    "num_win_h = H // window_size # Number of windows along height axis\n",
    "num_win_w = W // window_size # Number of windows along width axis\n",
    "q, k, v = map(\n",
    "    lambda t: rearrange(t, 'b (num_win_h win_h) (num_win_w win_w) (h d) -> b h (num_win_h num_win_w) (win_h win_w) d',\n",
    "                        h=num_heads,\n",
    "                        win_h=window_size,\n",
    "                        win_w=window_size), qkv)\n",
    "print('Q', q.shape)\n",
    "print('K', k.shape)\n",
    "print('V', v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed99926-469e-47f8-a3f1-2e192623e495",
   "metadata": {},
   "source": [
    "The tensor is structured as\n",
    "- Batch size: 4\n",
    "- Number of heads: 8\n",
    "- Number of windows: 16,\n",
    "- Number of patches per window: 16\n",
    "- Head dimension: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f09e89c7-4218-4e11-82d3-921fcf76f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product torch.Size([4, 8, 16, 16, 16])\n",
      "tensor([[ 0.7100,  0.8800,  1.0900,  0.5600,  1.8900,  1.7700,  1.0700,  0.6800,\n",
      "          1.3700, -0.2300,  0.6400,  1.7000,  1.4900,  0.4600,  0.9400,  0.6600],\n",
      "        [ 0.6400,  0.5700,  0.4400,  0.2000,  1.3600,  1.4600,  1.1700,  0.7900,\n",
      "          1.1700,  0.0700, -0.2100,  1.1500,  1.5100,  0.9400,  1.3700,  1.3700],\n",
      "        [ 1.9200,  0.9300,  1.7700,  0.7800,  2.0600,  2.1400,  2.3500,  1.4700,\n",
      "          1.5600,  0.9100,  0.6800,  2.2600,  2.0600,  1.6800,  2.0800,  2.1200],\n",
      "        [ 0.1100,  0.2800, -0.1200, -0.4800,  0.9900,  0.8100,  0.5700, -0.2700,\n",
      "          0.9100, -0.8200, -0.4000,  0.7100,  1.1400,  0.3500,  0.6800,  0.5900],\n",
      "        [ 0.4600,  0.7800,  0.2900,  0.1200,  1.6800,  1.4300,  0.4400,  0.6100,\n",
      "          0.8400, -0.4200,  0.1200,  0.9300,  1.2500, -0.0900,  0.8400,  0.6900],\n",
      "        [ 1.3000,  1.2900,  1.1500,  0.7600,  1.8600,  1.7900,  1.9400,  1.2700,\n",
      "          1.4100,  0.4400,  0.3200,  1.9200,  2.0300,  1.5700,  1.7100,  1.7700],\n",
      "        [ 1.8000,  2.1200,  2.3000,  1.8500,  2.2000,  2.8900,  1.7800,  1.8300,\n",
      "          2.1600,  0.4000,  1.6400,  2.1500,  2.8300,  1.3600,  2.4700,  1.8100],\n",
      "        [ 1.4000,  1.6000,  1.3300,  0.7900,  2.6800,  2.3200,  1.7900,  1.9600,\n",
      "          2.4800,  0.8000,  1.8700,  2.2300,  2.1900,  1.4900,  2.2900,  2.3700],\n",
      "        [-0.0700,  0.6200,  0.1500,  0.7300,  1.4000,  1.4300,  0.5900,  0.2600,\n",
      "          1.1900, -0.7500,  0.0400,  0.8900,  1.3600, -0.1400,  0.8900, -0.1400],\n",
      "        [ 0.3100,  0.1700,  0.7500,  0.1700,  0.7500,  1.6300,  0.4900,  0.1400,\n",
      "          0.6500, -0.5100, -0.1500,  1.0700,  1.9000,  0.4300,  0.4300,  1.2600],\n",
      "        [-0.0600, -0.0100, -0.7600, -0.2000,  1.7600,  0.9500,  0.8200, -0.7500,\n",
      "          0.9800, -1.3800, -0.3300,  0.4100,  1.4500, -0.5100,  0.7300, -0.3600],\n",
      "        [-0.5400, -0.4400, -0.2600, -0.4200,  0.9000,  0.8500,  0.1600, -0.5700,\n",
      "         -0.0000, -0.6300, -1.4500,  0.8200,  0.9800, -0.0900, -0.0600,  0.1900],\n",
      "        [ 0.8600,  0.8600,  1.1700,  0.8300,  1.9300,  2.3200,  1.7300,  0.8600,\n",
      "          1.5800, -0.5300,  0.0900,  1.7300,  2.8900,  1.0800,  1.5100,  1.0000],\n",
      "        [ 1.3300,  1.3100,  2.0900,  1.3000,  2.2100,  2.2300,  1.7200,  1.4500,\n",
      "          2.0500,  0.3400,  0.5300,  2.5100,  2.3500,  1.6100,  1.8400,  1.3600],\n",
      "        [ 1.2200,  1.7000,  1.4300,  0.8000,  3.1600,  2.9300,  1.6700,  1.3500,\n",
      "          2.3200,  0.2000,  0.8700,  2.4600,  2.7900,  1.1900,  2.2000,  1.5100],\n",
      "        [-0.6800, -0.5700, -0.5300, -0.4300,  0.5800,  0.6400, -0.0900, -1.2400,\n",
      "         -0.4400, -1.3600, -1.4600, -0.1600,  0.9900, -0.9500, -0.0900, -0.4100]],\n",
      "       grad_fn=<RoundBackward1>)\n",
      "Apply mask tensor([[0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Results tensor([[ 1.4700,  2.3500,  1.8100,  0.9000,  2.0200,  1.6400,  0.5400,  1.2900,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 2.0800,  2.2900,  2.3600,  1.0200,  2.1400,  2.1600,  1.4600,  1.4800,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 1.3900,  1.7000,  0.9700, -0.0800,  1.0100,  0.6200, -0.3200,  0.4700,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 1.9300,  2.6200,  1.9200,  0.6600,  1.5400,  1.0300,  1.2400,  1.9200,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 1.3500,  2.2200,  1.8100,  0.4500,  1.4500,  1.1500,  0.3300,  1.6700,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 2.5800,  2.4900,  3.2000,  2.1500,  2.4600,  2.5500,  1.8700,  2.7800,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 2.4500,  2.4000,  2.7000,  1.2500,  2.5100,  2.1700,  1.8300,  2.3300,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 2.0400,  2.1400,  1.7600,  0.9300,  1.2900,  1.1200,  0.5500,  1.1400,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          1.4300,  1.0600,  0.4900,  1.4900,  0.8200,  0.8100,  1.3700,  3.5800],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          0.0600, -0.0300, -1.3300,  1.0100, -0.8200, -0.7000, -0.2300,  1.4700],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          0.6200,  0.4100, -0.3400,  0.8600, -1.0100, -0.3300, -0.1900,  1.9200],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          0.6400,  1.0500, -0.7600,  1.1200, -0.1600,  0.2300,  0.6100,  2.0100],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          1.4000,  2.0600,  0.8700,  2.2600,  0.6100,  1.2800,  1.7400,  2.9900],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          1.3100,  1.2900, -0.1300,  2.1900,  0.2500,  0.8200,  1.4500,  3.0900],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          1.7500,  2.2000,  0.5600,  2.6800,  0.9700,  1.0700,  2.0300,  3.2600],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          1.0100,  1.3900, -0.2400,  1.4800,  0.1600,  0.9100,  0.9600,  2.0800]],\n",
      "       grad_fn=<RoundBackward1>)\n",
      "Apply mask tensor([[0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
      "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
      "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
      "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
      "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
      "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
      "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
      "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
      "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
      "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
      "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
      "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
      "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
      "        [0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf],\n",
      "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.],\n",
      "        [-inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0., -inf, -inf, 0., 0.]])\n",
      "Results tensor([[ 1.4700,  2.3500,    -inf,    -inf,  2.0200,  1.6400,    -inf,    -inf,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 2.0800,  2.2900,    -inf,    -inf,  2.1400,  2.1600,    -inf,    -inf,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [   -inf,    -inf,  0.9700, -0.0800,    -inf,    -inf, -0.3200,  0.4700,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [   -inf,    -inf,  1.9200,  0.6600,    -inf,    -inf,  1.2400,  1.9200,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 1.3500,  2.2200,    -inf,    -inf,  1.4500,  1.1500,    -inf,    -inf,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 2.5800,  2.4900,    -inf,    -inf,  2.4600,  2.5500,    -inf,    -inf,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [   -inf,    -inf,  2.7000,  1.2500,    -inf,    -inf,  1.8300,  2.3300,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [   -inf,    -inf,  1.7600,  0.9300,    -inf,    -inf,  0.5500,  1.1400,\n",
      "            -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          1.4300,  1.0600,    -inf,    -inf,  0.8200,  0.8100,    -inf,    -inf],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          0.0600, -0.0300,    -inf,    -inf, -0.8200, -0.7000,    -inf,    -inf],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "            -inf,    -inf, -0.3400,  0.8600,    -inf,    -inf, -0.1900,  1.9200],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "            -inf,    -inf, -0.7600,  1.1200,    -inf,    -inf,  0.6100,  2.0100],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          1.4000,  2.0600,    -inf,    -inf,  0.6100,  1.2800,    -inf,    -inf],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "          1.3100,  1.2900,    -inf,    -inf,  0.2500,  0.8200,    -inf,    -inf],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "            -inf,    -inf,  0.5600,  2.6800,    -inf,    -inf,  2.0300,  3.2600],\n",
      "        [   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "            -inf,    -inf, -0.2400,  1.4800,    -inf,    -inf,  0.9600,  2.0800]],\n",
      "       grad_fn=<RoundBackward1>)\n",
      "Final attention torch.Size([4, 16, 16, 1024])\n"
     ]
    }
   ],
   "source": [
    "q_dot_k = einsum('b h w i d, b h w j d -> b h w i j', q, k)\n",
    "print('Dot Product', q_dot_k.shape)\n",
    "print(torch.round(q_dot_k[0, 0, 0, :, :], decimals=2))\n",
    "\n",
    "print(\"Apply mask\", torch.round(upper_lower_mask))\n",
    "q_dot_k[:, :, -num_win_w:] += upper_lower_mask\n",
    "print(\"Results\", torch.round(q_dot_k[0, 0, -1, :, :], decimals=2))\n",
    "\n",
    "print(\"Apply mask\", torch.round(left_right_mask))\n",
    "q_dot_k[:, :, num_win_w - 1::num_win_w] += left_right_mask\n",
    "print(\"Results\", torch.round(q_dot_k[0, 0, -1, :, :], decimals=2))\n",
    "\n",
    "softmax_qk = q_dot_k.softmax(dim=-1)\n",
    "attn = einsum(\"b h w i j, b h w j d -> b h w i d\", softmax_qk, v)\n",
    "attn = rearrange(\n",
    "    attn,\n",
    "    \"b h (num_win_h num_win_w) (win_h win_w) d -> b (num_win_h win_h) (num_win_w win_w) (h d)\",\n",
    "    h=num_heads,\n",
    "    win_h=window_size,\n",
    "    win_w=window_size,\n",
    "    num_win_h=num_win_h,\n",
    "    num_win_w=num_win_w,\n",
    ")\n",
    "attn = shift_backward(attn)\n",
    "print('Final attention', attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c32d44-9949-4811-851f-90140ba76658",
   "metadata": {},
   "source": [
    "The final attention will organize the data back into patches. Each patch has an attention score that is comprised of `(num_of_heads, head_dim)` which is `8*128=1024`. Then it goes through a final linear mapping to reduce dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "125b97a5-8a90-42a1-9ffa-d35ebab0ad46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 16, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = to_out(attn)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f7ce8fb-24e4-4d6f-8ad3-5a05844bea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(B, H, W, embed_dim)\n",
    "attn = WindowAttention(embed_dim=embed_dim, num_heads=num_heads, head_dim=head_dim, shifted=True, window_size=window_size, relative_pos_embedding=True)(x)\n",
    "print(attn.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
