{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6011f1dc-36b7-4ded-91dc-b4f71a8cf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, reduce, repeat\n",
    "from torch import einsum, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab6d80-d43a-438c-a551-ae1c2f827910",
   "metadata": {
    "tags": []
   },
   "source": [
    "# einops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a7cb7-0c86-4b27-a6e3-cf676d4ebbe9",
   "metadata": {},
   "source": [
    "## Re-arrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d82f8-1805-4803-8229-1917f25286ee",
   "metadata": {},
   "source": [
    "This is same as `permute`. I can shift an axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53e3855-4071-4ef1-8b78-e37e3a5dde51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 1080, 1920, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = rearrange(x, 'b c h w -> b h w c')\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd82f64-b0b3-409b-a840-c4fa2a129b0a",
   "metadata": {},
   "source": [
    "This is same as view. I can collapse some axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa4cfae-c1c0-4739-bd75-7e82b2b539a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 3, 2073600])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = rearrange(x, 'b c h w -> b c (h w)')\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550a15fe-886f-424b-bf08-bd708c0c61b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 3, 135, 8, 1920])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = rearrange(x, 'b c (h1 h2) w -> b c h1 h2 w', h2=8)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16454410-89a5-47a0-a958-3c110cfa14ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16])\n",
      "torch.Size([4, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(16, 16)\n",
    "print(x.shape)\n",
    "x = rearrange(x, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=4, h2=4)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91292585-5e61-4305-a06d-2a26e9c10e0b",
   "metadata": {},
   "source": [
    "## Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630e35b-7ca6-4e77-9069-56faa3d82e87",
   "metadata": {},
   "source": [
    "Repeat is like `torch.expand`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448433d7-c18b-42f0-9821-990373117630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 2, 1080, 1920, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = repeat(x, 'b c h w -> b repeat h w c', repeat=2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db44d3b-b33e-4165-919a-c2ddcbc3585a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 2160, 3840, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = repeat(x, 'b c h w -> b (2 h) (2 w) c')\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d9d804-9e11-418a-9592-f77f74ed6ac9",
   "metadata": {},
   "source": [
    "## Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e1058-a963-4174-a809-136346e479ed",
   "metadata": {},
   "source": [
    "Reduce is the opposite of repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b02e7c9-6fe2-4867-9a36-4aa46a13c85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5002, 0.5004, 0.4998],\n",
       "        [0.5001, 0.5000, 0.5000],\n",
       "        [0.5000, 0.4997, 0.5000],\n",
       "        [0.4998, 0.4997, 0.5000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = reduce(x, 'b c h w -> b c', 'mean')\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f212fde3-c671-48b5-8094-6ae04e1f92fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = reduce(x, 'b c h w -> b c', 'max')\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0f905c8-fff5-453f-b302-b308d01a4d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.2517e-06, 1.9670e-06, 1.1921e-07],\n",
       "        [1.1921e-07, 2.3842e-07, 2.3842e-07],\n",
       "        [0.0000e+00, 1.7881e-07, 3.5763e-07],\n",
       "        [1.0133e-06, 2.3842e-07, 0.0000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = reduce(x, 'b c h w -> b c', 'min')\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dafe75fe-ae67-4cc9-8d0c-850a6226df66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1080, 1920])\n",
      "torch.Size([4, 1080, 1920])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 3, 1080, 1920)\n",
    "print(x.shape)\n",
    "x = reduce(x, 'b c h w -> b h w', 'mean')\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67fe18-3559-4923-928a-086c4a92d3e0",
   "metadata": {},
   "source": [
    "## Concrete Example with Attention Head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5d702-a121-4b19-a793-407d78ac38bc",
   "metadata": {},
   "source": [
    "Suppose I have 8 by 8 patches, each patch has an embedding dimension, I will group them into multiple windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe6f49e2-b4fb-4340-bc62-25161a2b71f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([4, 8, 8, 512]), torch.Size([4, 8, 8, 512]), torch.Size([4, 8, 8, 512])]\n",
      "(batch_size, num_heads, num_windows, num_patches, head_dim) torch.Size([4, 8, 4, 16, 64])\n",
      "(batch_size, num_heads, num_windows, num_patches, head_dim) torch.Size([4, 8, 4, 16, 64])\n",
      "(batch_size, num_heads, num_windows, num_patches, head_dim) torch.Size([4, 8, 4, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32\n",
    "head_dim = 64\n",
    "num_heads = 8\n",
    "window_size = 4\n",
    "\n",
    "x = torch.rand(4, 8, 8, 32) # Patch tensor with shape (batch, height, width, embedding dim)\n",
    "to_qkv = nn.Linear(embed_dim, 3 * num_heads * head_dim) # Each Q, K, V has multiple heads.\n",
    "\n",
    "B, H, W, _ = x.shape\n",
    "\n",
    "qkv = to_qkv(x).chunk(3, dim=-1)\n",
    "print([t.shape for t in qkv])\n",
    "\n",
    "window_height = H // window_size\n",
    "window_width = W // window_size\n",
    "\n",
    "for t in qkv:\n",
    "    t_prime = rearrange(t, 'b (num_win_h win_h) (num_win_w win_w) (h d) -> b h (num_win_h num_win_w) (win_h win_w) d',\n",
    "                        h=num_heads, d=head_dim, win_h=window_size, win_w=window_size)\n",
    "    print('(batch_size, num_heads, num_windows, num_patches, head_dim)', t_prime.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8d72e-6331-483f-86b5-23e958f86b19",
   "metadata": {},
   "source": [
    "# einsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ca04a-a8fa-47b8-bdc6-a142830cb215",
   "metadata": {},
   "source": [
    "Re-use the attention head example from above. I will a dot product to compute the attention score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "148d33ac-f605-42d2-bc43-782471386bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 4, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "q = torch.randn(4, 8, 4, 16, 64)\n",
    "k = torch.randn(4, 8, 4, 16, 64)\n",
    "v = torch.randn(4, 8, 4, 16, 64)\n",
    "\n",
    "# Dot product along (16, 16) or (i, j).\n",
    "dot_product = einsum('b h w i d, b h w j d -> b h w i j', q, k)\n",
    "print(dot_product.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d65764-137c-4c8d-abf0-9a454e854d1c",
   "metadata": {},
   "source": [
    "More dot product example (outer dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "214037c3-d3dd-408f-ad31-3f4b66adcb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4096., 4096., 4096., 4096., 4096., 4096., 4096., 4096., 4096., 4096.,\n",
       "        4096., 4096., 4096., 4096., 4096., 4096.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones(16, 64)\n",
    "B = torch.ones(16, 64)\n",
    "einsum('n i, n j -> n', A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12e03f3-2b15-4bcd-aeb4-99e7fc756b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones(4, 16, 64)\n",
    "B = torch.ones(4, 16, 64)\n",
    "einsum('n i d, n j d -> n i j', A, B).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8bf9c-eecf-4d14-ac12-8f1f13f74b6f",
   "metadata": {},
   "source": [
    "Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aaadaf6-a16d-48a9-8f5a-4c0a7e65d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(4, 2, 5)\n",
    "B = torch.rand(4, 5, 4)\n",
    "einsum('b i j, b j k -> b i k', A, B).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102dccd2-1a19-4db7-b5d1-1188fc16764f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
