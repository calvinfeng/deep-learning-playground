{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2503a6a5-690d-4b75-a5d9-6d41e6786fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba307db-6a5c-454f-9f76-e2675d8f9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from swin.transformer import SwinBlock, PatchMerging, StageModule, swin_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfb2b0-c20b-4a69-93cd-b36e8fa0c77f",
   "metadata": {},
   "source": [
    "# Swin Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c17fde-93c9-4b8b-b852-2c09b2c3d1b6",
   "metadata": {},
   "source": [
    "Each swin block contains a residual window attention and feed forward layer. Two successive swin blocks will create a transformer stage.\n",
    "\n",
    "![Swin Block](swin-block.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd77df5c-498e-4cfd-8035-8bbe20921ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "in_channels = 3\n",
    "hidden_dim = 96\n",
    "patch_size = 4 # Same as downscaling factor\n",
    "window_size = 7\n",
    "head_dim = 32\n",
    "num_heads = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9f3580-53a7-4016-8124-38298e6716fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dim, downscaling_factor=patch_size)\n",
    "normal_block = SwinBlock(embed_dim=hidden_dim, num_heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dim * 4, shifted=False,\n",
    "                         window_size=window_size, relative_pos_embedding=True)\n",
    "shifted_block = SwinBlock(embed_dim=hidden_dim, num_heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dim * 4, shifted=True,\n",
    "                          window_size=window_size, relative_pos_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654ef24c-3ca6-4b76-9c52-f27b3131a1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch partition torch.Size([1, 56, 56, 96])\n",
      "Swin Block torch.Size([1, 56, 56, 96])\n",
      "Shifted Swin Block torch.Size([1, 56, 56, 96])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, in_channels, img_height, img_width)\n",
    "x = patch_partition(x)\n",
    "print(\"Patch partition\", x.shape)\n",
    "x = normal_block(x)\n",
    "print(\"Swin Block\", x.shape)\n",
    "x = shifted_block(x)\n",
    "print(\"Shifted Swin Block\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36796d62-ebb0-4d47-919c-f5e69cfe383c",
   "metadata": {},
   "source": [
    "Now we have 49 by 49 patches, each patch has 96 hidden dimension, after factoring in attention and position embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e782fab-dfd8-488e-89c2-129056acca46",
   "metadata": {},
   "source": [
    "# Transformer Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494ce4ac-1cb9-4073-bea1-0174483e3e51",
   "metadata": {},
   "source": [
    "Each stage can contain multiple Swin blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c19e30-1807-4944-9372-182da516ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "hidden_dim = 96\n",
    "output_dim = 21\n",
    "\n",
    "stage_1 = StageModule(\n",
    "    in_channels=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    layers=2,\n",
    "    downscaling_factor=4,\n",
    "    num_heads=3,\n",
    "    head_dim=32,\n",
    "    window_size=7,\n",
    "    relative_pos_embedding=True)\n",
    "\n",
    "stage_2 = StageModule(\n",
    "    in_channels=hidden_dim,\n",
    "    hidden_dim=hidden_dim * 2,\n",
    "    layers=2,\n",
    "    downscaling_factor=2,\n",
    "    num_heads=6,\n",
    "    head_dim=32,\n",
    "    window_size=7,\n",
    "    relative_pos_embedding=True)\n",
    "\n",
    "stage_3 = StageModule(\n",
    "    in_channels=hidden_dim * 2,\n",
    "    hidden_dim=hidden_dim * 4,\n",
    "    layers=6,\n",
    "    downscaling_factor=2,\n",
    "    num_heads=12,\n",
    "    head_dim=32,\n",
    "    window_size=7,\n",
    "    relative_pos_embedding=True)\n",
    "\n",
    "stage_4 = StageModule(\n",
    "    in_channels=hidden_dim * 4,\n",
    "    hidden_dim=hidden_dim * 8,\n",
    "    layers=2,\n",
    "    downscaling_factor=2,\n",
    "    num_heads=24,\n",
    "    head_dim=32,\n",
    "    window_size=7,\n",
    "    relative_pos_embedding=True)\n",
    "\n",
    "mlp_head = nn.Sequential(nn.LayerNorm(hidden_dim * 8), nn.Linear(hidden_dim * 8, output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abaed940-4d4d-4c00-8ce6-b88945d1ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1: torch.Size([1, 96, 56, 56])\n",
      "Stage 2: torch.Size([1, 192, 28, 28])\n",
      "Stage 3: torch.Size([1, 384, 14, 14])\n",
      "Stage 4: torch.Size([1, 768, 7, 7])\n",
      "Reduce x via averaging last 2 dimensions torch.Size([1, 768])\n",
      "Output: torch.Size([1, 21])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 224, 224)\n",
    "x = stage_1(x)\n",
    "print(\"Stage 1:\", x.shape)\n",
    "x = stage_2(x)\n",
    "print(\"Stage 2:\", x.shape)\n",
    "x = stage_3(x)\n",
    "print(\"Stage 3:\", x.shape)\n",
    "x = stage_4(x)\n",
    "print(\"Stage 4:\", x.shape)\n",
    "x = x.mean(dim=[2, 3])\n",
    "print(\"Reduce x via averaging last 2 dimensions\", x.shape)\n",
    "x = mlp_head(x)\n",
    "print(\"Output:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f076fc-9877-4bfa-8b7d-16956235eb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_swin_model = swin_t()\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "y = tiny_swin_model(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6fb86-e809-4ebe-baea-cb0df0d890fa",
   "metadata": {},
   "source": [
    "# Transformer as Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "228dcd95-952e-40e4-8c15-e6911ffc220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swin.model import SwinTransformerBackbone, TransformerCenterNet\n",
    "from ssd.model import SingleShotDetector\n",
    "from centernet.model import CenterNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a6ffde-4212-412d-9f62-3a236a609156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 112, 112])\n",
      "torch.Size([1, 192, 56, 56])\n",
      "torch.Size([1, 384, 28, 28])\n",
      "torch.Size([1, 768, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "backbone = SwinTransformerBackbone(\n",
    "    channels=3,\n",
    "    hidden_dim=96,\n",
    "    layers=(2, 2, 6, 2),\n",
    "    heads=(3, 6, 12, 24),\n",
    "    window_size=7,\n",
    "    downscaling_factors=(2, 2, 2, 1)\n",
    ")\n",
    "\n",
    "stage_1 = StageModule(\n",
    "    in_channels=3,\n",
    "    hidden_dim=96,\n",
    "    layers=2,\n",
    "    downscaling_factor=2,\n",
    "    num_heads=3,\n",
    "    head_dim=32,\n",
    "    window_size=7,\n",
    "    relative_pos_embedding=True)\n",
    "\n",
    "stage_2 = StageModule(\n",
    "    in_channels=96,\n",
    "    hidden_dim=96 * 2,\n",
    "    layers=2,\n",
    "    downscaling_factor=2,\n",
    "    num_heads=6,\n",
    "    head_dim=32,\n",
    "    window_size=7,\n",
    "    relative_pos_embedding=True)\n",
    "\n",
    "\n",
    "stage_3 = StageModule(\n",
    "    in_channels=96 * 2,\n",
    "    hidden_dim=96 * 4,\n",
    "    layers=2,\n",
    "    downscaling_factor=2,\n",
    "    num_heads=6,\n",
    "    head_dim=32,\n",
    "    window_size=7,\n",
    "    relative_pos_embedding=True)\n",
    "\n",
    "stage_4 = StageModule(\n",
    "    in_channels=96 * 4,\n",
    "    hidden_dim=96 * 8,\n",
    "    layers=2,\n",
    "    downscaling_factor=1,\n",
    "    num_heads=6,\n",
    "    head_dim=32,\n",
    "    window_size=7,\n",
    "    relative_pos_embedding=True)\n",
    "\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "x = stage_1(x)\n",
    "print(x.shape)\n",
    "x = stage_2(x)\n",
    "print(x.shape)\n",
    "x = stage_3(x)\n",
    "print(x.shape)\n",
    "x = stage_4(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c9b36e-f7f5-402d-aa72-034710486270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 56, 56])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 448, 448)\n",
    "backbone(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d40139a-7bdc-4788-b91b-85de66c791ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification torch.Size([1, 21, 56, 56])\n",
      "Regression torch.Size([1, 4, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerCenterNet()\n",
    "x = torch.rand(1, 3, 448, 448)\n",
    "cls, reg = transformer(x)\n",
    "print(\"Classification\", cls.shape)\n",
    "print(\"Regression\", reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78565ff9-b78f-4f5e-9dbe-73a28b6614b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer 30888497\n",
      "Centernet 18917977\n",
      "SSD 26284974\n"
     ]
    }
   ],
   "source": [
    "centernet = CenterNet()\n",
    "ssd = SingleShotDetector()\n",
    "\n",
    "print(\"Transformer\", sum(p.numel() for p in transformer.parameters()))\n",
    "print(\"Centernet\", sum(p.numel() for p in centernet.parameters()))\n",
    "print(\"SSD\", sum(p.numel() for p in ssd.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2daec20-0d9e-4998-b9fc-aef2a0dec4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
